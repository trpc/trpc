---
title: AI
description: Integrate AI functionality to Fumadocs.
---

## Docs for LLM

You can make your docs site more AI-friendly with dedicated docs content for large language models.

First, make a `getLLMText` function that converts pages into static MDX content:

<include>./get-llm-text.ts</include>

> Modify it to include other remark plugins.

### `llms.txt`

A version of docs for AIs to read.

<include meta='title="app/llms.txt/route.ts"'>./llms.txt.ts</include>

### `*.mdx`

Allow people to append `.mdx` to a page to get its Markdown/MDX content.

Make a route handler to return page content.

<include meta='title="app/llms.mdx/[[...slug]]/route.ts"'>
  ./llms.mdx.ts
</include>

And redirect users to that route.

```ts title="next.config.ts"
import type { NextConfig } from 'next';

const config: NextConfig = {
  async rewrites() {
    return [
      {
        source: '/docs/:path*.mdx',
        destination: '/llms.mdx/:path*',
      },
    ];
  },
};
```

## AI Search

![AI Search](/docs/ai-search.png)

You can install the AI search dialog using Fumadocs CLI:

```package-install
npx @fumadocs/cli add
```

By default, it's configured for Inkeep AI. Since it's connected via Vercel AI SDK, you can connect to your own AI models easily.

> Note that Fumadocs doesn't provide the AI model, it's up to you.
